{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 171, 340]\n",
      "[4, 191, 316]\n",
      "[4, 204, 307]\n",
      "[4, 216, 302]\n",
      "[4, 227, 304]\n",
      "[4, 236, 306]\n",
      "[4, 243, 319]\n",
      "[4, 253, 331]\n",
      "[4, 261, 338]\n",
      "[4, 267, 336]\n",
      "[4, 273, 339]\n",
      "[4, 278, 345]\n",
      "[4, 284, 354]\n",
      "[4, 289, 362]\n",
      "[4, 296, 368]\n",
      "[4, 300, 371]\n",
      "[4, 300, 366]\n",
      "[4, 297, 361]\n",
      "[4, 294, 358]\n",
      "[4, 289, 354]\n",
      "[4, 287, 352]\n",
      "[4, 285, 349]\n",
      "[4, 283, 346]\n",
      "[4, 281, 343]\n",
      "[4, 280, 341]\n",
      "[4, 279, 338]\n",
      "[4, 277, 338]\n",
      "[4, 276, 336]\n",
      "[4, 273, 335]\n",
      "[4, 272, 334]\n",
      "[4, 272, 334]\n",
      "[4, 270, 334]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import time\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "\n",
    "class handDetector() :\n",
    "\n",
    "    def __init__(self , mode = False , maxHands =2 , detectionCon = 0.5 , trackCon = 0.5 ):\n",
    "        self.mode = mode\n",
    "        self.maxHands = maxHands\n",
    "        self.detectionCon = detectionCon\n",
    "        self.trackCon = trackCon\n",
    "\n",
    "        self.mpHands = mp.solutions.hands\n",
    "        self.hands = self.mpHands.Hands(\n",
    "            self.mode,\n",
    "            self.maxHands,\n",
    "            min_detection_confidence=self.detectionCon,\n",
    "            min_tracking_confidence=self.trackCon\n",
    "        )\n",
    "\n",
    "        self.mpDraw = mp.solutions.drawing_utils\n",
    "\n",
    "# FIRST FUNCTION\n",
    "\n",
    "    def findHands(self , img , draw = True ) :\n",
    "\n",
    "        imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        self.results = self.hands.process(imgRGB)\n",
    "        # we have a warning here cuz the function only exists after running the code to give the hand position\n",
    "        # we made the print in a if statement to avoid the none value if there is no hands\n",
    "\n",
    "        if self.results.multi_hand_landmarks:\n",
    "            for handLms in self.results.multi_hand_landmarks:\n",
    "                if draw :\n",
    "                    self.mpDraw.draw_landmarks(img, handLms, self.mpHands.HAND_CONNECTIONS)\n",
    "        return img\n",
    "\n",
    "# SECOND FUNCTION\n",
    "\n",
    "    def findPosition(self , img , handNo =0 , draw =True ):\n",
    "\n",
    "        lmList = []\n",
    "\n",
    "        if self.results.multi_hand_landmarks:\n",
    "        #Here we only used one hand , the first position , we can adjust it to use multiple hands if we want\n",
    "            myHand = self.results.multi_hand_landmarks[handNo]\n",
    "            for id, lm in enumerate(myHand.landmark):\n",
    "                # here we have the positions , basically we took the h , w of the image and multiply\n",
    "                # each element with appropriate value to get the exact pixel\n",
    "                h, w, c = img.shape\n",
    "                cx, cy = int(lm.x * w), int(lm.y * h)\n",
    "                # print(id, cx, cy)\n",
    "                lmList.append([id , cx ,cy])\n",
    "                # if id == 4:\n",
    "                #     cv2.circle(img, (cx, cy), 15, (120, 255, 0), cv2.FILLED)\n",
    "\n",
    "        return lmList\n",
    "\n",
    "\n",
    "def main():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    pTime = 0\n",
    "    cTime = 0\n",
    "    detector = handDetector()\n",
    "\n",
    "    while True:\n",
    "        success, img = cap.read()\n",
    "        # Just flipping the image here\n",
    "        img = cv2.flip(img, 1)\n",
    "        cTime = time.time()\n",
    "        fps = 1 / (cTime - pTime)\n",
    "        pTime = cTime\n",
    "\n",
    "        img = detector.findHands(img)\n",
    "        lmList = detector.findPosition(img)\n",
    "\n",
    "        if len(lmList) != 0:\n",
    "            print(lmList[4])  # Test with point 4 on the hand\n",
    "\n",
    "        cv2.putText(img, str(int(fps)), (10, 70), cv2.FONT_HERSHEY_PLAIN, 3,\n",
    "                    (120, 120, 80), 3)\n",
    "        cv2.imshow(\"Web Cam Image\", img)\n",
    "\n",
    "        # Check if the 'q' key is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release the capture and close all OpenCV windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\" :\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
